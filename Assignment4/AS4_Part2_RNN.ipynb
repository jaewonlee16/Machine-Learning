{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCj2f3K0AopU"
   },
   "source": [
    "# M2608.001300 기계학습 기초 및 전기정보 응용<br> Assignment #4 Part 2: Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3h2lj90AwRM"
   },
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Bong-Gyun Kang, May 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4FBjC8BAzzG"
   },
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "Now, you're going to leave behind your implementations and instead migrate to one of popular deep learning frameworks, **PyTorch**. <br>\n",
    "\n",
    "In this notebook, you will learn how to train a Recurrent Neural Network (RNN) for sequential modeling. Specifically, you will build a character-level RNN to generate names from different languages. <br> \n",
    "You need to follow the instructions to **complete 6 TODO sections and explain them if needed.**\n",
    "\n",
    "You will see:\n",
    "- how to implement a character-level RNN in PyTorch;\n",
    "- train the network; and\n",
    "- sampling sequences from the network.\n",
    "\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results. \n",
    "\n",
    "\n",
    "### Some helpful tutorials and references for assignment #4:\n",
    "- [1] Pytorch official documentation. [[link]](https://pytorch.org/docs/stable/index.html)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/\n",
    "- [4] https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Za9xcdsGyUJG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssxKD8OqyUJM"
   },
   "source": [
    "Preparing the Data\n",
    "==================\n",
    "\n",
    "Note:\n",
    "   Extract the ``rnn_data.zip`` to the current directory.\n",
    "\n",
    "The dataset has a bunch of plain text files ``data/names/[Language].txt`` with a\n",
    "name per line. We split lines into an array, convert Unicode to ASCII,\n",
    "and end up with a dictionary ``{language: [names ...]}``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7VPv_zWQ41M"
   },
   "source": [
    "Execute the following 2 cells if you are using Google Colab, otherwise just skip. Rename the statement after `cd` with your current directory (e.g. `cd /content/drive/your/current/directory/`). Refer to Assignment1's data loading sceme if you have troubles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eP0jN4H9yYSa"
   },
   "outputs": [],
   "source": [
    "# Execute this and below cell if you are using Google Colab, otherwise just skip.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5M57T-ghyfT8"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hVTrHs23yUJN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Chinese', 'Greek', 'French', 'Italian', 'Russian', 'Portuguese', 'Polish', 'Japanese', 'Korean', 'Czech', 'Spanish', 'Irish', 'Vietnamese', 'Arabic', 'German', 'English', 'Scottish', 'Dutch']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded rnn_data.zip '\n",
    "        'from eTL and extract it to the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hFURVnRyUJO"
   },
   "source": [
    "Problem 1. Creating the Network\n",
    "====================\n",
    "\n",
    "**TODO 1**: Instead of using ``torch.nn.RNN``, build your own RNN network.\n",
    "\n",
    "RNN architecture in order:\n",
    "- ``i2h`` : a linear layer for the hidden\n",
    "- ``i2o`` : a linear layer for the output\n",
    "- ``o2o`` : a linear layer after combining hidden and output\n",
    "- ``dropout`` : randomly zeros parts of its\n",
    "input <https://arxiv.org/abs/1207.0580>`__ with a given probability\n",
    "(here 0.1) and is usually used to fuzz inputs to prevent overfitting.\n",
    "- ``softmax`` : LogSoftmax for the final output\n",
    "\n",
    "Category tensor is a one-hot vector just like the letter input and it is concatenated with the input and hidden. Output is interpreted as the probability of the next letter. When sampling, the most likely output letter is used as the next input letter.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d5iB_dJvyUJO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        ##############################################################################\n",
    "        #                          IMPLEMENT YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_concat = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_concat)\n",
    "        \n",
    "        ##############################################################################\n",
    "        #                          END OF YOUR CODE                                  #\n",
    "        ##############################################################################\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG_zviJQyUJP"
   },
   "source": [
    "Training\n",
    "=========\n",
    "Preparing for Training\n",
    "----------------------\n",
    "\n",
    "First of all, helper functions to get random pairs of (category, line):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bFkFsGqdyUJP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeSqd029yUJQ"
   },
   "source": [
    "For each timestep (that is, for each letter in a training word) the\n",
    "inputs of the network will be\n",
    "``(category, current letter, hidden state)`` and the outputs will be\n",
    "``(next letter, next hidden state)``. So for each training set, we'll\n",
    "need the category, a set of input letters, and a set of output/target\n",
    "letters.\n",
    "\n",
    "Since we are predicting the next letter from the current letter for each\n",
    "timestep, the letter pairs are groups of consecutive letters from the\n",
    "line - e.g. for ``\"ABCD<EOS>\"`` we would create (\"A\", \"B\"), (\"B\", \"C\"),\n",
    "(\"C\", \"D\"), (\"D\", \"EOS\").\n",
    "\n",
    "The category tensor is a `one-hot\n",
    "tensor`__ of size\n",
    "``<1 x n_categories>``. When training we feed it to the network at every\n",
    "timestep - this is a design choice, it could have been included as part\n",
    "of initial hidden state or some other strategy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UWd85nz5yUJQ"
   },
   "outputs": [],
   "source": [
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-kSvhdYyUJQ"
   },
   "source": [
    "For convenience during training we'll make a ``randomTrainingExample``\n",
    "function that fetches a random (category, line) pair and turns them into\n",
    "the required (category, input, target) tensors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zf11xJrByUJR"
   },
   "outputs": [],
   "source": [
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GtX3mGeB1u_0"
   },
   "outputs": [],
   "source": [
    "category, line = randomTrainingPair()\n",
    "category_tensor = categoryTensor(category)\n",
    "input_line_tensor = inputTensor(line)\n",
    "target_line_tensor = targetTensor(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Nb52i4wU156Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Dutch', 'Maes')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category, line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iuDg6euyUJR"
   },
   "source": [
    "Problem 2. Training the Network\n",
    "--------------------\n",
    "\n",
    "In contrast to classification, where only the last output is used, we\n",
    "are making a prediction at every step, so we are calculating loss at\n",
    "every step.\n",
    "\n",
    "The magic of autograd allows you to simply sum these losses at each step\n",
    "and call backward at the end.\n",
    "\n",
    "**TODO 2**: Define a loss function, learning rate and hidden size for RNN training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A08N0a3syUJR"
   },
   "outputs": [],
   "source": [
    "# Define a loss function, learning rate, hidden size\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "learning_rate = 0.0005\n",
    "n_hidden = 128\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "rnn = RNN(n_letters, n_hidden, n_letters)\n",
    "\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vzqJELsyUJS"
   },
   "source": [
    "To keep track of how long training takes I am adding a\n",
    "``timeSince(timestamp)`` function which returns a human readable string:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DBc1XIUgyUJS"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k12OIBVqyUJS"
   },
   "source": [
    "Training is business as usual - call train a bunch of times and wait a\n",
    "few minutes, printing the current time and loss every ``print_every``\n",
    "examples, and keeping store of an average loss per ``plot_every`` examples\n",
    "in ``all_losses`` for plotting later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I3g12ICHyUJT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 6s (5000 5%) 2.4502\n",
      "0m 13s (10000 10%) 2.5936\n",
      "0m 19s (15000 15%) 2.0203\n",
      "0m 26s (20000 20%) 1.8849\n",
      "0m 32s (25000 25%) 2.3129\n",
      "0m 39s (30000 30%) 2.9481\n",
      "0m 46s (35000 35%) 3.0483\n",
      "0m 52s (40000 40%) 2.6644\n",
      "0m 58s (45000 45%) 2.0645\n",
      "1m 5s (50000 50%) 2.3832\n",
      "1m 11s (55000 55%) 2.6286\n",
      "1m 17s (60000 60%) 1.8435\n",
      "1m 23s (65000 65%) 1.3536\n",
      "1m 30s (70000 70%) 2.0662\n",
      "1m 36s (75000 75%) 2.7435\n",
      "1m 42s (80000 80%) 2.2908\n",
      "1m 48s (85000 85%) 2.0660\n",
      "1m 55s (90000 90%) 2.4593\n",
      "2m 1s (95000 95%) 2.1312\n",
      "2m 7s (100000 100%) 2.4394\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, n_hidden, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "torch.save(rnn.state_dict(), 'RNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rf_bwthyUJT"
   },
   "source": [
    "Plotting the Losses\n",
    "-------------------\n",
    "\n",
    "Plotting the historical loss from all\\_losses shows the network\n",
    "learning:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lN2PkUXzyUJT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff70d210190>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocldE9xuyUJT"
   },
   "source": [
    "Problem 3. Sampling from the Network\n",
    "====================\n",
    "\n",
    "**TODO 3**: To sample we give the network a letter and ask what the next one is,\n",
    "feed that in as the next letter, and repeat until the EOS token.\n",
    "\n",
    "-  Create tensors for input category, starting letter, and empty hidden\n",
    "   state\n",
    "-  Create a string ``output_name`` with the starting letter\n",
    "-  Up to a maximum output length,\n",
    "\n",
    "   -  Feed the current letter to the network\n",
    "   -  Get the next letter from highest output, and next hidden state\n",
    "   -  If the letter is EOS, stop here\n",
    "   -  If a regular letter, add to ``output_name`` and continue\n",
    "\n",
    "-  Return the final name\n",
    "\n",
    ".. Note::\n",
    "   Rather than having to give it a starting letter, another\n",
    "   strategy would have been to include a \"start of string\" token in\n",
    "   training and have the network choose its own starting letter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rcV_uJWjyUJU"
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(category, start_letter='A'):\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)  # Convert category to tensor\n",
    "        input_tensor = inputTensor(start_letter)  # Convert start letter to tensor\n",
    "        hidden_state = rnn.initHidden()  # Initialize the hidden state\n",
    "\n",
    "        output_name = start_letter  # Start the output name with the initial letter\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            output, hidden_state = rnn(category_tensor, input_tensor[0], hidden_state)  # Forward pass\n",
    "            top_value, top_index = output.topk(1)  # Get the top value and index\n",
    "            top_index = top_index.item()  # Convert tensor to scalar\n",
    "\n",
    "            if top_index == n_letters - 1:  # If the EOS token is reached, stop generation\n",
    "                break\n",
    "            else:\n",
    "                predicted_letter = all_letters[top_index]  # Get the corresponding letter\n",
    "                output_name += predicted_letter  # Append the letter to the output name\n",
    "\n",
    "            input_tensor = inputTensor(predicted_letter)  # Update the input tensor for the next iteration\n",
    "    \n",
    "    \n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZlvPetDeOEv"
   },
   "source": [
    "**TODO 4**: Sample 12 different names from 4 languages (i.e. 3 names per language). Use the ``samples`` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GkBGxJ7-eMIs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allan\n",
      "Barin\n",
      "Chanton\n",
      "Dernen\n",
      "Ering\n",
      "Ferren\n",
      "Garan\n",
      "Haran\n",
      "Ianer\n",
      "Jon\n",
      "Kon\n",
      "Lon\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "samples('Russian', 'ABC')\n",
    "samples('German', 'DEF')\n",
    "samples('Spanish', 'GHI')\n",
    "samples('Korean', 'JKL')\n",
    "\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET-ZRw41mcu6"
   },
   "source": [
    "Problem 4. Comparing HMM and RNN\n",
    "====================\n",
    "So far, we have conducted practical exercises on HMM and RNN. Here, we will compare the similarities and differences between the two models and additionally try using Chat-GPT, which has recently emerged as a powerful tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuQyf5b0mdqo"
   },
   "source": [
    "**TODO 5**: \n",
    "Please describe two or more commonalities and differences between HMM and RNN\n",
    "\n",
    "<br>\n",
    "write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonalities Between HMM and RNN\n",
    "1. Sequential Data Processing:\n",
    "Both HMMs and RNNs are adept at managing sequential data. HMMs approach this by modeling the probabilistic dependencies between sequential states, operating under the assumption that the system follows a Markov process with hidden states. On the other hand, RNNs utilize their recurrent structure to handle sequences, maintaining information about previous elements to capture dependencies over time.\n",
    "\n",
    "2. State Representation:\n",
    "In both models, the concept of state is central. HMMs have hidden states that probabilistically emit observations, with transitions governed by state transition probabilities. Similarly, RNNs maintain hidden states, updated recurrently based on the current input and the previous hidden state, but in a deterministic manner rather than a probabilistic one.\n",
    "\n",
    "Differences Between HMM and RNN\n",
    "1. Nature of the Models:\n",
    "HMMs are fundamentally probabilistic models. They define explicit probability distributions for state transitions and observations, involving a clear mathematical formulation with states, transition probabilities, and emission probabilities. Conversely, RNNs are deterministic neural networks. Their state transitions and outputs are determined by learned parameters (weights), and they rely on backpropagation through time (BPTT) for training.\n",
    "\n",
    "2. Hidden Markov Models (HMMs) are more straightforward compared to Recurrent Neural Networks (RNNs) and are built on strong assumptions that might not always hold true. If these assumptions are valid, HMMs can often perform better because they are less complex and easier to implement effectively. On the other hand, RNNs can yield superior performance with very large datasets due to their added complexity, which allows them to leverage the vast amount of information more effectively. This advantage holds even if HMMs’ assumptions are applicable in your situation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK7wVhx9mf2R"
   },
   "source": [
    "Now we are going to use Chat-GPT to answer the following questions. There are two main ways to use Chat-GPT. The first is to use the web version. You can easily use version 3.5 by signing up at https://chat.openai.com/. The second is to use the OpenAI API. If you sign up for the paid version or if you are a new user, you will be provided with a certain amount of credits, so interested students can give it a try. Detailed information about the API version can be found at https://platform.openai.com/docs/guides/chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TttTvST5mitn"
   },
   "source": [
    "**TODO 6**: \n",
    "\n",
    "Let's use Chat-GPT to answer the following questions. \n",
    "- Provide two or more commonalities and differences between HMM and RNN\n",
    "- Explain the event in which HMM performed better than RNN in stock market prediction right before Korea's IMF\n",
    "\n",
    "Report the generated answer and write your satisfaction with answers.\n",
    "\n",
    "<br>\n",
    "write your answer here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commonalities Between HMM and RNN\n",
    "1. Sequential Data Handling:\n",
    "    - HMM (Hidden Markov Model): HMMs are designed to model sequential data by capturing the probabilistic dependencies between states in a sequence. They assume that the system being modeled is a Markov process with hidden states.\n",
    "    - RNN (Recurrent Neural Network): RNNs are also used to process sequential data, leveraging their recurrent structure to maintain information about previous elements in the sequence, allowing them to capture dependencies over time.\n",
    "\n",
    "2. State Representation:\n",
    "    - HMM: In HMMs, the sequence of states is hidden, and each state emits an observation according to a certain probability distribution. The model involves transitions between hidden states and the emission of observations from these states.\n",
    "    - RNN: In RNNs, the hidden state at each time step is a deterministic function of the previous hidden state and the current input. The hidden state is updated recurrently as new inputs are processed.\n",
    "\n",
    "## Differences Between HMM and RNN\n",
    "1. Model Type:\n",
    "\n",
    "    - HMM: HMMs are probabilistic models that use explicit probability distributions for state transitions and observations. They are defined by a set of states, transition probabilities, and emission probabilities.\n",
    "    - RNN: RNNs are deterministic neural network models that use learned parameters (weights) to determine the state transitions and outputs. They rely on backpropagation through time (BPTT) for training.\n",
    "2. Learning Mechanism:\n",
    "\n",
    "    - HMM: The parameters of HMMs (transition probabilities, emission probabilities) are typically learned using algorithms like the Expectation-Maximization (EM) algorithm, particularly the Baum-Welch algorithm.\n",
    "    - RNN: RNNs are trained using gradient-based optimization techniques. The gradients are computed via backpropagation through time (BPTT), which involves unfolding the network through time and applying backpropagation.\n",
    "3. Expressiveness:\n",
    "\n",
    "    - HMM: HMMs have a limited capacity to model complex dependencies due to their reliance on a fixed number of hidden states and predefined probability distributions. They are well-suited for simpler, more interpretable models.\n",
    "    - RNN: RNNs, particularly when extended with architectures like LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Unit), are more powerful and capable of modeling long-range dependencies and complex patterns in data. They can learn from large datasets and capture intricate temporal dynamics.\n",
    "4. Interpretability:\n",
    "\n",
    "    - HMM: HMMs are more interpretable due to their explicit probabilistic nature. The transition and emission probabilities provide clear insights into the model's behavior and the relationships between states and observations.\n",
    "    - RNN: RNNs, while powerful, are often considered \"black-box\" models. The learned weights and activations within the network do not provide straightforward interpretability regarding how the model makes predictions.\n",
    "In summary, both HMMs and RNNs are used to model sequential data, but they differ significantly in their underlying principles, learning mechanisms, expressiveness, and interpretability. HMMs are probabilistic and interpretable but limited in complexity, while RNNs are deterministic, powerful, and capable of learning complex patterns, albeit less interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the event in which HMM performed better than RNN in stock market prediction right before Korea's IMF\n",
    "In the context of stock market prediction, there was a notable instance where Hidden Markov Models (HMMs) outperformed Recurrent Neural Networks (RNNs) leading up to the Asian Financial Crisis, commonly referred to as the IMF crisis, which affected South Korea in 1997. Here’s an exploration of why HMMs might have performed better in this specific scenario:\n",
    "\n",
    "Context and Background\n",
    "Before delving into the details, it's essential to understand the economic environment of South Korea right before the IMF crisis. The South Korean stock market was experiencing significant volatility due to political instability, economic imbalances, and speculative investments. The market conditions were highly uncertain, making prediction models particularly challenging to apply.\n",
    "\n",
    "Why HMMs Outperformed RNNs\n",
    "1. Simplicity and Strong Assumptions:\n",
    "HMMs rely on the assumption that the market can be modeled with a set of discrete hidden states (e.g., bull market, bear market, and stable market). Each state has certain probabilities of transitioning to another state and generating observed data (e.g., stock prices). In a highly volatile and relatively short-term period leading up to the crisis, these assumptions can sometimes capture the regime shifts more effectively than the more flexible but complex RNNs.\n",
    "\n",
    "2. Limited Data and Overfitting:\n",
    "RNNs require large amounts of data to learn effectively and can easily overfit when data is sparse or highly noisy, which was the case before the IMF crisis. HMMs, being simpler models, are less prone to overfitting and can generalize better in situations with limited or noisy data.\n",
    "\n",
    "3. Clear Regime Shifts:\n",
    "The period leading up to the crisis involved clear regime shifts due to economic policies, foreign exchange pressures, and political events. HMMs are particularly good at detecting and modeling such regime shifts, as they are explicitly designed to work with sequences where the underlying state changes over time. RNNs, while powerful, might struggle to identify these shifts without extensive tuning and large datasets.\n",
    "\n",
    "4. Interpretability:\n",
    "HMMs provide a clearer interpretability of market states and transitions, which can be crucial during periods of economic uncertainty. Investors and analysts can better understand the probabilities of different market regimes and make more informed decisions based on the model’s output. RNNs, although capable of capturing complex patterns, act more like a black box, making it harder to interpret the results during such critical times.\n",
    "\n",
    "Specific Event Example\n",
    "Right before the IMF crisis, South Korea’s stock market exhibited significant fluctuations due to the rapid outflow of foreign capital and the devaluation of the Korean won. An HMM could identify and model the transitions between different market states (e.g., high volatility to crash) more effectively by observing patterns and making probabilistic predictions about the next state. This clear demarcation of states provided better predictive performance compared to RNNs, which may not have had enough data to train effectively and could have been misled by the noise and rapid changes in the market.\n",
    "\n",
    "In conclusion, HMMs outperformed RNNs in predicting the South Korean stock market right before the IMF crisis due to their ability to handle regime shifts, simplicity in modeling with limited data, resistance to overfitting, and interpretability during volatile periods. These characteristics made HMMs more suitable for the specific conditions of the market leading up to the crisis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
